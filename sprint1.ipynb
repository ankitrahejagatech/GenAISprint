{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitrahejagatech/GenAISprint/blob/main/sprint1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I975U49NvDec",
        "outputId": "26f455ae-1b44-48f8-df0b-0ef84ebe155e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.8)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.79)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.111.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.30.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (2.1.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Ensure the necessary libraries are installed\n",
        "!pip install langchain openai chromadb pandas requests tiktoken langchain-community\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your valid API key\n",
        "\n",
        "# Sample CSV data for a single user's daily healthcare information over 7 days\n",
        "csv_data = \"\"\"\n",
        "date,time,blood_pressure,sugar_level,steps,calories_burned,notes\n",
        "2024-06-08,08:00,120/80,90,500,50,Felt good after morning walk.\n",
        "2024-06-08,10:00,115/78,85,300,30,Had a light breakfast.\n",
        "2024-06-08,12:00,118/80,95,200,20,Worked at desk.\n",
        "2024-06-08,14:00,122/82,100,100,10,Lunch with friends.\n",
        "2024-06-08,16:00,125/85,110,150,15,Afternoon snack.\n",
        "2024-06-08,18:00,120/80,105,400,40,Evening walk.\n",
        "2024-06-08,20:00,115/78,98,250,25,Dinner at home.\n",
        "2024-06-08,22:00,118/80,92,100,10,Read a book before bed.\n",
        "2024-06-07,08:00,130/85,95,450,45,Felt tired in the morning.\n",
        "2024-06-07,10:00,125/80,90,250,25,Had a big breakfast.\n",
        "2024-06-07,12:00,120/80,100,150,15,Worked at desk.\n",
        "2024-06-07,14:00,123/83,105,100,10,Lunch alone.\n",
        "2024-06-07,16:00,126/87,115,100,10,Felt sleepy.\n",
        "2024-06-07,18:00,122/80,110,350,35,Evening run.\n",
        "2024-06-07,20:00,118/78,105,200,20,Light dinner.\n",
        "2024-06-07,22:00,116/79,97,100,10,Watched TV before bed.\n",
        "2024-06-06,08:00,125/82,85,500,50,Morning walk.\n",
        "2024-06-06,10:00,118/80,80,300,30,Healthy breakfast.\n",
        "2024-06-06,12:00,120/82,90,200,20,Desk work.\n",
        "2024-06-06,14:00,123/84,95,150,15,Lunch with colleagues.\n",
        "2024-06-06,16:00,122/80,105,150,15,Afternoon tea.\n",
        "2024-06-06,18:00,120/78,100,400,40,Evening jog.\n",
        "2024-06-06,20:00,115/76,95,250,25,Home dinner.\n",
        "2024-06-06,22:00,117/78,90,150,15,Read book before bed.\n",
        "2024-06-05,08:00,130/85,100,400,40,Feeling tired.\n",
        "2024-06-05,10:00,125/80,95,300,30,Skipped breakfast.\n",
        "2024-06-05,12:00,120/82,105,200,20,Worked through lunch.\n",
        "2024-06-05,14:00,124/85,110,100,10,Quick lunch.\n",
        "2024-06-05,16:00,126/86,120,150,15,Afternoon meeting.\n",
        "2024-06-05,18:00,122/80,115,350,35,Evening gym.\n",
        "2024-06-05,20:00,118/78,108,200,20,Light dinner.\n",
        "2024-06-05,22:00,116/79,100,100,10,Watched movie.\n",
        "2024-06-04,08:00,125/82,90,500,50,Morning run.\n",
        "2024-06-04,10:00,120/80,85,300,30,Healthy breakfast.\n",
        "2024-06-04,12:00,118/80,95,200,20,Desk work.\n",
        "2024-06-04,14:00,122/82,100,100,10,Lunch with friends.\n",
        "2024-06-04,16:00,125/85,110,150,15,Afternoon walk.\n",
        "2024-06-04,18:00,120/80,105,400,40,Evening jog.\n",
        "2024-06-04,20:00,115/78,98,250,25,Dinner at home.\n",
        "2024-06-04,22:00,118/80,92,100,10,Read book before bed.\n",
        "2024-06-03,08:00,130/85,95,450,45,Morning yoga.\n",
        "2024-06-03,10:00,125/80,90,250,25,Big breakfast.\n",
        "2024-06-03,12:00,120/80,100,150,15,Worked at desk.\n",
        "2024-06-03,14:00,123/83,105,100,10,Lunch alone.\n",
        "2024-06-03,16:00,126/87,115,100,10,Afternoon nap.\n",
        "2024-06-03,18:00,122/80,110,350,35,Evening run.\n",
        "2024-06-03,20:00,118/78,105,200,20,Light dinner.\n",
        "2024-06-03,22:00,116/79,97,100,10,Watched TV.\n",
        "2024-06-02,08:00,125/82,85,500,50,Felt great after morning walk.\n",
        "2024-06-02,10:00,118/80,80,300,30,Healthy breakfast.\n",
        "2024-06-02,12:00,120/82,90,200,20,Desk work.\n",
        "2024-06-02,14:00,123/84,95,150,15,Lunch with colleagues.\n",
        "2024-06-02,16:00,122/80,105,150,15,Afternoon tea.\n",
        "2024-06-02,18:00,120/78,100,400,40,Evening jog.\n",
        "2024-06-02,20:00,115/76,95,250,25,Home dinner.\n",
        "2024-06-02,22:00,117/78,90,150,15,Read book before bed.\n",
        "\"\"\"\n",
        "\n",
        "# Configuration parameters\n",
        "CONFIG = {\n",
        "    \"csv_data\": csv_data,  # Directly use the sample CSV data\n",
        "    \"csv_fields\": [\"date\", \"time\", \"blood_pressure\", \"sugar_level\", \"steps\", \"calories_burned\", \"notes\"],  # Fields to use from CSV files\n",
        "    \"chunk_strategy\": \"recursive\",  # options: \"character\", \"recursive\"\n",
        "    \"chunk_size\": 1000,  # Size of each chunk\n",
        "    \"chunk_overlap\": 200,  # Overlap size between chunks\n",
        "    \"embedding_model\": \"text-embedding-ada-002\",  # Using text-embedding-ada-002 for embeddings\n",
        "    \"top_k_responses\": 5,  # Number of top responses to retrieve\n",
        "    \"clean_data\": True,  # Whether to clean data\n",
        "    \"advanced_retrieval\": True,  # Whether to use advanced retrieval strategies\n",
        "    \"rerank_responses\": True,  # Whether to rerank responses\n",
        "    \"use_rewriter\": True,  # Whether to use a rewriter for the query\n",
        "    \"embedding_engine_type\": \"openai\",  # Type of embedding engine to use, e.g., \"openai\"\n",
        "    \"query_prompt\": \"How was my health today, and has this improved in the last 7 days?\"  # Query prompt to be used\n",
        "}\n",
        "\n",
        "def load_documents(config):\n",
        "    \"\"\"Load and process CSV data into documents.\"\"\"\n",
        "    from langchain.schema import Document\n",
        "    documents = []\n",
        "\n",
        "    # Load CSV data\n",
        "    print(\"Loading CSV data...\")\n",
        "    df = pd.read_csv(StringIO(config[\"csv_data\"]))\n",
        "    # Ensure all fields are strings before joining\n",
        "    df[config[\"csv_fields\"]] = df[config[\"csv_fields\"]].astype(str)\n",
        "    text_data = df[config[\"csv_fields\"]].apply(lambda x: ' '.join(x.dropna()), axis=1).tolist()\n",
        "    for text in text_data:\n",
        "        # Create Document objects with text as page_content\n",
        "        documents.append(Document(page_content=text, metadata={}))\n",
        "    print(f\"Loaded {len(documents)} documents.\")\n",
        "    return documents\n",
        "\n",
        "def clean_documents(documents):\n",
        "    \"\"\"Clean and preprocess documents.\"\"\"\n",
        "    print(\"Cleaning documents...\")\n",
        "    cleaned_documents = documents  # Placeholder for cleaning logic\n",
        "    print(\"Documents cleaned.\")\n",
        "    return cleaned_documents\n",
        "\n",
        "def chunkify_documents(documents, strategy=\"character\", chunk_size=1000, overlap=200):\n",
        "    \"\"\"Split documents into chunks using the specified strategy.\"\"\"\n",
        "    print(\"Chunkifying documents...\")\n",
        "    if strategy == \"character\":\n",
        "        text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "    elif strategy == \"recursive\":\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "    chunks = []\n",
        "    for doc in documents:\n",
        "        # Use dot notation to access 'page_content' attribute\n",
        "        chunks.extend(text_splitter.split_text(doc.page_content))\n",
        "    print(f\"Created {len(chunks)} chunks.\")\n",
        "    return chunks\n",
        "\n",
        "def embed_chunks(chunks, embedding_model, embedding_engine_type=\"openai\"):\n",
        "    \"\"\"Embed the chunks using the specified embedding model and engine.\"\"\"\n",
        "    print(f\"Embedding chunks using {embedding_engine_type} engine with model {embedding_model}...\")\n",
        "    if embedding_engine_type == \"openai\":\n",
        "        embedding_engine = OpenAIEmbeddings(model=embedding_model)\n",
        "    else:\n",
        "        embedding_engine = None  # Placeholder for other embedding engines\n",
        "\n",
        "    # Ensure chunks are strings before embedding\n",
        "    chunks = [str(chunk) for chunk in chunks]  # Convert each chunk to string explicitly\n",
        "\n",
        "    embeddings = embedding_engine.embed_documents(chunks)\n",
        "    print(f\"Embedded {len(chunks)} chunks.\")\n",
        "    return embeddings, embedding_engine\n",
        "\n",
        "def store_in_vectordb(documents, embeddings, embedding_engine):\n",
        "    \"\"\"Store the embeddings in a Chroma vector database.\"\"\"\n",
        "    print(\"Storing embeddings in VectorDB...\")\n",
        "\n",
        "    # Initialize Chroma with the embedding function\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embedding_engine  # Pass the embedding engine to Chroma\n",
        "    )\n",
        "\n",
        "    print(\"Embeddings stored in VectorDB.\")\n",
        "    return vectordb\n",
        "\n",
        "def rewrite_query(query):\n",
        "    \"\"\"Rewrite the query to improve retrieval performance.\"\"\"\n",
        "    print(\"Rewriting query...\")\n",
        "    rewritten_query = query  # Placeholder for rewriting logic\n",
        "    print(f\"Original query: {query}\")\n",
        "    print(f\"Rewritten query: {rewritten_query}\")\n",
        "    return rewritten_query\n",
        "\n",
        "def advanced_retrieve(vectordb, query_embedding, top_k=5):\n",
        "    \"\"\"Retrieve documents using advanced retrieval strategies.\"\"\"\n",
        "    print(\"Using advanced retrieval strategies...\")\n",
        "    responses = vectordb.similarity_search(query_embedding, k=top_k)\n",
        "    return responses\n",
        "\n",
        "def rerank_responses(responses):\n",
        "    \"\"\"Rerank the responses to improve accuracy.\"\"\"\n",
        "    print(\"Reranking responses...\")\n",
        "    reranked_responses = responses  # Placeholder for reranking logic\n",
        "    return reranked_responses\n",
        "\n",
        "def validate_response(response):\n",
        "    \"\"\"Validate the response to ensure it meets criteria.\"\"\"\n",
        "    print(\"Validating response...\")\n",
        "    validated_response = response  # Placeholder for validation logic\n",
        "    print(\"Response validated.\")\n",
        "    return validated_response\n",
        "\n",
        "def guardrail_validation(question):\n",
        "    \"\"\"Validate the input question for safety and appropriateness.\"\"\"\n",
        "    print(\"Validating input question...\")\n",
        "    validated_question = question  # Placeholder for guardrail logic\n",
        "    print(\"Input question validated.\")\n",
        "    return validated_question\n",
        "\n",
        "# Main RAG function\n",
        "def run_rag_pipeline(config):\n",
        "    \"\"\"Run the RAG pipeline from loading documents to retrieving and validating responses.\"\"\"\n",
        "    print(\"Starting RAG process...\")\n",
        "\n",
        "    # Load and process documents\n",
        "    documents = load_documents(config)\n",
        "\n",
        "    # Clean documents if specified\n",
        "    if config[\"clean_data\"]:\n",
        "        documents = clean_documents(documents)\n",
        "\n",
        "    # Chunkify documents\n",
        "    chunks = chunkify_documents(documents, strategy=config[\"chunk_strategy\"], chunk_size=config[\"chunk_size\"], overlap=config[\"chunk_overlap\"])\n",
        "\n",
        "    # Embed chunks\n",
        "    embeddings, embedding_engine = embed_chunks(chunks, config[\"embedding_model\"], config[\"embedding_engine_type\"])\n",
        "\n",
        "    # Store embeddings in VectorDB\n",
        "    vectordb = store_in_vectordb(documents, embeddings, embedding_engine)\n",
        "\n",
        "    # Define the input question from config\n",
        "    question = config[\"query_prompt\"]\n",
        "\n",
        "    # Validate the input question\n",
        "    question = guardrail_validation(question)\n",
        "\n",
        "    # Rewrite query if specified\n",
        "    if config[\"use_rewriter\"]:\n",
        "        question = rewrite_query(question)\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = embedding_engine.embed_query(question)\n",
        "\n",
        "    # Retrieve responses\n",
        "    if config[\"advanced_retrieval\"]:\n",
        "        responses = advanced_retrieve(vectordb, query_embedding, top_k=config[\"top_k_responses\"])\n",
        "    else:\n",
        "        responses = vectordb.similarity_search(query_embedding, k=config[\"top_k_responses\"])\n",
        "\n",
        "    # Rerank responses if specified\n",
        "    if config[\"rerank_responses\"]:\n",
        "        responses = rerank_responses(responses)\n",
        "\n",
        "    # Validate and print responses\n",
        "    for response, score in responses:\n",
        "        validated_response = validate_response(response)\n",
        "        print(f\"Response: {validated_response}\\nScore: {score}\\n\")\n",
        "\n",
        "    print(\"RAG process completed.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    run_rag_pipeline(CONFIG)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "0OlWLx7z0bv9",
        "outputId": "d4604e38-a406-4ae2-879d-31de09d69c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting RAG process...\n",
            "Loading CSV data...\n",
            "Loaded 56 documents.\n",
            "Cleaning documents...\n",
            "Documents cleaned.\n",
            "Chunkifying documents...\n",
            "Created 56 chunks.\n",
            "Embedding chunks using openai engine with model text-embedding-ada-002...\n",
            "Embedded 56 chunks.\n",
            "Storing embeddings in VectorDB...\n",
            "Embeddings stored in VectorDB.\n",
            "Validating input question...\n",
            "Input question validated.\n",
            "Rewriting query...\n",
            "Original query: How was my health today, and has this improved in the last 7 days?\n",
            "Rewritten query: How was my health today, and has this improved in the last 7 days?\n",
            "Using advanced retrieval strategies...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or buffer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-53314ced32b9>\u001b[0m in \u001b[0;36m<cell line: 234>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mrun_rag_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-53314ced32b9>\u001b[0m in \u001b[0;36mrun_rag_pipeline\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;31m# Retrieve responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"advanced_retrieval\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madvanced_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectordb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"top_k_responses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectordb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"top_k_responses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-53314ced32b9>\u001b[0m in \u001b[0;36madvanced_retrieve\u001b[0;34m(vectordb, query_embedding, top_k)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;34m\"\"\"Retrieve documents using advanced retrieval strategies.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using advanced retrieval strategies...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectordb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36msimilarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0mmost\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquery\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         docs_and_scores = self.similarity_search_with_score(\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36msimilarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m             )\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             results = self.__query_collection(\n\u001b[1;32m    440\u001b[0m                 \u001b[0mquery_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \"\"\"\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maembed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m#       than the maximum context and use length-safe embedding function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_len_safe_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     async def aembed_documents(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    469\u001b[0m                     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 token = encoding.encode(\n\u001b[0m\u001b[1;32m    472\u001b[0m                     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0mallowed_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowed_special\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tiktoken/core.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_special_token_regex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mraise_disallowed_special_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
          ]
        }
      ]
    }
  ]
}